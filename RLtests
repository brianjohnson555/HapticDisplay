import os
import gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.evaluation import evaluate_policy

# Load environment
env_name = 'CartPole-v1'
env = gym.make(env_name)

def Test(episodes,env,model):
    for episode in range(1,episodes+1):
        obs = env.reset()
        done = False
        score = 0

        while not done:
            env.render()
            action, _states = model.predict(obs)
            obs, reward, done, info = env.step(action)
            score += reward
        print('Episode:{} Score:{}'.format(episode, score))
    env.close()

PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model_cartpole')

Training = True
log_path = os.path.join('Training','Logs')
if Training:

    # Define algorithm
    env = DummyVecEnv([lambda: env])
    model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)

    # Learning
    model.learn(total_timesteps=20000)

    # Save model
    model.save(PPO_path)

# Load model
model = PPO.load(PPO_path, env=env)
# evaluate_policy(model, env, n_eval_episodes=10, render=True)
Test(5, env, model)

training_log_path = os.path.join(log_path,'PPO_2')
# tensorboard --logdir={training_log_path}